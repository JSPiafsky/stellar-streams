{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f15ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from stellar_stream import StellarStream\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load all simulations into StellarStream type and put in a dictionary for easy access.\n",
    "\n",
    "from pathlib import Path\n",
    "p = Path('../../data/sample')\n",
    "\n",
    "simulations = {}\n",
    "\n",
    "for sim_data in p.glob('*.npz'):\n",
    "    simulation_number = sim_data.name.removeprefix('simdatag').removesuffix('.npz')\n",
    "    simulations[simulation_number] = (StellarStream.from_simulation(simulation_number, sim_data)\n",
    "                                            .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "                                            .select(\"restrict_phi2\", phi2_lim=15.0)\n",
    "                                            # .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "                                            .run_analysis(name=\"gaussian_process_detrend\", n_bins=40)\n",
    "                                            .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "                                            .select(\"restrict_phi2\", phi2_lim=6.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bff05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations['717'].plot_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(x, a, b):\n",
    "        return a * x**b\n",
    "\n",
    "\n",
    "def linear(x, m, b):\n",
    "        return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5389b8",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_simulations_fixed_slope(\n",
    "    simulations,\n",
    "    ids,\n",
    "    skip_first_xbin=True,\n",
    "    last_n_for_c: int = 10,\n",
    "    min_positive_points: int = 6,\n",
    "    ddof_std: int = 0,\n",
    "    compute_amp_err: bool = True,\n",
    "    fit_band: tuple | None = None,  # (xmin, xmax) in same units as x (e.g. Hz). Use None for no band filtering.\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      simulations: dict-like mapping id (str/int) -> StellarStream object\n",
    "      ids: iterable of ids (strings or ints)\n",
    "      skip_first_xbin: whether to drop the first bin\n",
    "      last_n_for_c: how many last bins define the floor c\n",
    "      min_positive_points: minimum (#) positive points after subtracting c to attempt a fit\n",
    "      ddof_std: ddof for std_vlos\n",
    "      compute_amp_err: whether to estimate an error on amplitude (simple standard error in log domain)\n",
    "      fit_band: optional tuple (xmin, xmax). If provided, only points with xmin <= x <= xmax are used for the fits.\n",
    "                Example: fit_band=(0.1, 1.0) will fit only between 0.1 and 1.0 Hz.\n",
    "    Returns:\n",
    "      df, mean_slope, (pearson_r, pearson_p), fig\n",
    "    \"\"\"\n",
    "    ids_list = [str(i) for i in list(ids)]\n",
    "    rows = []\n",
    "    fit_cache = {}  # store x,y,c,y_sub,b,a,log_a for each successful sim\n",
    "\n",
    "    for sid in ids_list:\n",
    "        if sid not in simulations:\n",
    "            # skip missing sims quietly\n",
    "            continue\n",
    "        sim = simulations[sid]\n",
    "        try:\n",
    "            #x, y = sim.power_spectrum(**kwargs)\n",
    "            x, y = sim.denoised_power_spectrum(**kwargs)\n",
    "        except Exception:\n",
    "            # skip sims that fail to produce a spectrum\n",
    "            continue\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        if skip_first_xbin:\n",
    "            x = x[1:]\n",
    "            y = y[1:]\n",
    "        # sort by x ascending (so last entries are highest-k)\n",
    "        order = np.argsort(x)\n",
    "        x_sorted = x[order]\n",
    "        y_sorted = y[order]\n",
    "        n = len(x_sorted)\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        # estimate c as mean of last_n_for_c y-values (highest-k)\n",
    "        last_n = min(last_n_for_c, n)\n",
    "        c_est = float(np.mean(y_sorted[-last_n:]))\n",
    "\n",
    "        # subtract c\n",
    "        y_sub = y_sorted - c_est\n",
    "\n",
    "        # keep only points with x>0 and y_sub>0 (required for log)\n",
    "        mask_pos = (x_sorted > 0) & (y_sub > 0) & np.isfinite(y_sub) & np.isfinite(x_sorted)\n",
    "\n",
    "        # apply user-specified band if given\n",
    "        if fit_band is not None:\n",
    "            xmin, xmax = fit_band\n",
    "            if xmin is not None:\n",
    "                mask_pos &= (x_sorted >= xmin)\n",
    "            if xmax is not None:\n",
    "                mask_pos &= (x_sorted <= xmax)\n",
    "\n",
    "        if np.sum(mask_pos) < min_positive_points:\n",
    "            # skip if too few usable bins after subtraction and band filtering\n",
    "            continue\n",
    "\n",
    "        x_pos = x_sorted[mask_pos]\n",
    "        y_pos = y_sub[mask_pos]\n",
    "\n",
    "        # log-log fit for slope b_i and intercept\n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "        # fit linear model ly = b * lx + intercept  (np.polyfit returns [b, intercept])\n",
    "        b_i, intercept = np.polyfit(lx, ly, 1)\n",
    "        log_a_i = intercept\n",
    "        a_i = float(np.exp(log_a_i))\n",
    "\n",
    "        # store (note: store the band-filtered x_pos/y_pos used for the fit)\n",
    "        fit_cache[sid] = {\n",
    "            \"x\": x_sorted,\n",
    "            \"y\": y_sorted,\n",
    "            \"c_est\": c_est,\n",
    "            \"x_pos\": x_pos,\n",
    "            \"y_pos\": y_pos,\n",
    "            \"b\": float(b_i),\n",
    "            \"log_a\": float(log_a_i),\n",
    "            \"a\": a_i\n",
    "        }\n",
    "        # std of line of sight velocities\n",
    "        try:\n",
    "            std_vlos = float(np.asarray(sim.vlos).std(ddof=ddof_std))\n",
    "        except Exception:\n",
    "            std_vlos = np.nan\n",
    "\n",
    "        rows.append({\"id\": sid, \"std_vlos\": std_vlos, \"b\": float(b_i), \"a\": a_i, \"c_est\": c_est})\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        raise RuntimeError(\"No successful fits found (too few positive points after c-subtraction / band filtering).\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 3) mean slope across sims\n",
    "    mean_b = float(df[\"b\"].mean())\n",
    "\n",
    "    # 4) Fix slope mean_b and recompute amplitude per sim (in log domain)\n",
    "    amplitudes = []\n",
    "    amp_errs = []\n",
    "    for sid in df[\"id\"].astype(str):\n",
    "        info = fit_cache[sid]\n",
    "        x_pos = info[\"x_pos\"]\n",
    "        y_pos = info[\"y_pos\"]\n",
    "        \n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "\n",
    "        p0_amp = [np.log(info.get('a', 1.0))]\n",
    "        popt_amp, pcov_amp = curve_fit(lambda x, a_prime: linear(x, mean_b, a_prime), lx, ly, p0=p0_amp, bounds=(-np.inf, np.inf), maxfev=20000)\n",
    "        a_hat = float(np.exp(popt_amp[0]))\n",
    "        if compute_amp_err and pcov_amp is not None:\n",
    "            perr = np.sqrt(np.diag(pcov_amp))\n",
    "            stderr_log_a = float(perr[0])               # std error on log(a)\n",
    "            amp_err = a_hat * stderr_log_a  \n",
    "        else:\n",
    "            amp_err = np.nan\n",
    "        \n",
    "        amplitudes.append(a_hat)\n",
    "        amp_errs.append(amp_err)\n",
    "\n",
    "    df[\"amplitude\"] = amplitudes\n",
    "    df[\"amp_err\"] = amp_errs\n",
    "\n",
    "    # Pearson correlation between std_vlos and amplitude\n",
    "    # require at least 2 valid points\n",
    "    mask_valid = np.isfinite(df[\"std_vlos\"]) & np.isfinite(df[\"amplitude\"])\n",
    "    if mask_valid.sum() >= 2:\n",
    "        r, pval = pearsonr(df.loc[mask_valid, \"std_vlos\"], df.loc[mask_valid, \"amplitude\"])\n",
    "    else:\n",
    "        r, pval = np.nan, np.nan\n",
    "\n",
    "    # Plot results: amplitude vs std_vlos with errorbars and linear fit line\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    xs = df[\"std_vlos\"].values\n",
    "    ys = df[\"amplitude\"].values\n",
    "    yerr = df[\"amp_err\"].values if \"amp_err\" in df.columns else None\n",
    "    ax.errorbar(xs, ys, yerr=yerr, fmt='o', capsize=3)\n",
    "    ax.set_xlabel(\"Std. Dev. of Line-of-Sight Velocity\")\n",
    "    ax.set_ylabel(\"Amplitude a (log-fit after c-subtraction)\")\n",
    "    ax.set_title(f\"Amplitude vs Std. Dev.  —  mean slope b = {mean_b:.3f}\\nPearson r={r:.3f}, p={pval:.3g}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # simple linear regression line for visualization (unweighted)\n",
    "    finite_mask = np.isfinite(xs) & np.isfinite(ys)\n",
    "    if finite_mask.sum() >= 2:\n",
    "        coeffs = np.polyfit(xs[finite_mask], ys[finite_mask], 1)\n",
    "        line_x = np.linspace(np.nanmin(xs[finite_mask]), np.nanmax(xs[finite_mask]), 200)\n",
    "        ax.plot(line_x, coeffs[0]*line_x + coeffs[1], label=f\"lin fit slope={coeffs[0]:.3g}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # annotate with ids (small offset)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.annotate(row[\"id\"], (row[\"std_vlos\"], row[\"amplitude\"]), textcoords=\"offset points\", xytext=(3,3), fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return df, mean_b, (r, pval), fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27550ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_to_use = list(filter(lambda k: k not in ['716', '712'], simulations.keys()))\n",
    "\n",
    "# df, mean_b, (r,p), fig = analyze_simulations_fixed_slope(\n",
    "#     simulations, \n",
    "#     simulations_to_use, \n",
    "#     last_n_for_c=2,\n",
    "#     fit_band=(0.05, 1), \n",
    "#     detrend='linear', \n",
    "#     precision=0.5, \n",
    "#     smooth=True, \n",
    "#     sigma=1, \n",
    "#     interpolate=True,\n",
    "#     window='hann')\n",
    "\n",
    "df, mean_b, (r,p), fig = analyze_simulations_fixed_slope(\n",
    "    simulations, \n",
    "    simulations_to_use, \n",
    "    last_n_for_c=5,\n",
    "    fit_band=(None, None),\n",
    "    #precision=0.5, \n",
    "    #smooth=True, \n",
    "    #sigma=1, \n",
    "    #interpolate=True\n",
    "    )\n",
    "df.head(); print(\"mean slope b:\", mean_b, \"pearson r,p:\", (r,p))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sim_power(df, sim_idx, include_first=True, loglog=True, ax=None):\n",
    "    \"\"\"\n",
    "    Plot power spectrum of one simulation against its fitted model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with fitted parameters. Must have columns:\n",
    "        ['a_hat', 'b'] for amplitude and slope.\n",
    "    sim_idx : int\n",
    "        Index (row number) of the simulation in df (and in arrays).\n",
    "    include_first: bool\n",
    "        If True, include the first data point in the plot. Gives\n",
    "        the option since it can skew the log-log plot.\n",
    "    loglog : bool\n",
    "        If True, plot in log-log scale.\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axis to plot on. Creates new one if None.\n",
    "    \"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "        \n",
    "    first=slice(None,None) if include_first else slice(1,None)\n",
    "\n",
    "    # grab data\n",
    "    k, ps = simulations[sim_idx].power_spectrum_denoised(precision=1.0, detrend='linear', smooth=True, sigma=2, interpolate=True, interpolation_resolution=2048)\n",
    "\n",
    "    # grab model parameters\n",
    "    a = df.loc[df['id'] == sim_idx, \"amplitude\"].iloc[0]\n",
    "    c = df.loc[df['id'] == sim_idx, \"c_est\"].iloc[0]\n",
    "\n",
    "    # compute model\n",
    "    b_mean = df['b'].mean()\n",
    "    ps_model = a * k**b_mean + c\n",
    "\n",
    "    mask = np.isfinite(ps_model)\n",
    "    k=k[mask]\n",
    "    ps_model=ps_model[mask]\n",
    "    ps=ps[mask]\n",
    "\n",
    "    # plot data\n",
    "    ax[0].plot(k[first], ps[first], 'o', ms=3, alpha=0.6, label=f\"Sim {sim_idx} data\")\n",
    "\n",
    "    # plot model\n",
    "    ax[0].plot(k[first], ps_model[first], 'r-', lw=2, label=f\"Model: P(k)={a:.2g} k^{b_mean:.2f} + {c:.2g}\")\n",
    "\n",
    "    if loglog:\n",
    "        ax[0].set_xscale(\"log\")\n",
    "        ax[0].set_yscale(\"log\")\n",
    "        \n",
    "        ax[1].set_xscale(\"log\")\n",
    "        ax[1].set_yscale(\"log\")\n",
    "\n",
    "    ax[0].set_xlabel(\"k\")\n",
    "    ax[0].set_ylabel(\"P(k)\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title(f\"Simulation {sim_idx}: slope={b_mean:.2f}\")\n",
    "\n",
    "    residuals = np.abs(ps[first] - ps_model[first]) if loglog else ps[first] - ps_model[first]\n",
    "\n",
    "    # plot residuals\n",
    "    ax[1].plot(k[first], residuals, 'o', ms=3, alpha=0.6, label=f\"Sim {sim_idx} residuals\")\n",
    "    ax[1].set_xlabel(\"k\")\n",
    "    ax[1].set_ylabel(\"Residuals\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392be501",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sim_power(df, '658', include_first=True, loglog=True)\n",
    "plot_sim_power(df, '663', include_first=True, loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "StellarStream.plot_power_spectrum_denoised(simulations['658'], simulations['578'], simulations['712'])\n",
    "StellarStream.plot_power_spectrum(simulations['658'], simulations['578'], simulations['712'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854af878",
   "metadata": {},
   "source": [
    "## Just Power Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_simulations_power_law(\n",
    "    simulations,\n",
    "    ids,\n",
    "    skip_first_xbin=True,\n",
    "    ddof_std: int = 0,\n",
    "    compute_amp_err: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      simulations: dict-like mapping id (str/int) -> StellarStream object\n",
    "      ids: iterable of ids (strings or ints)\n",
    "      skip_first_xbin: whether to drop the first bin\n",
    "      ddof_std: ddof for std_vlos\n",
    "      compute_amp_err: whether to estimate an error on amplitude (simple standard error in log domain)\n",
    "\n",
    "    Returns:\n",
    "      df, mean_slope, (pearson_r, pearson_p), fig\n",
    "    \"\"\"\n",
    "    ids_list = [str(i) for i in list(ids)]\n",
    "    rows = []\n",
    "    fit_cache = {}  # store x,y,c,y_sub,b,a,log_a for each successful sim\n",
    "\n",
    "    for sid in ids_list:\n",
    "        if sid not in simulations:\n",
    "            # skip missing sims quietly\n",
    "            continue\n",
    "        sim = simulations[sid]\n",
    "        try:\n",
    "            x, y = sim.power_spectrum_denoised(precision=1.0, detrend='linear')\n",
    "        except Exception:\n",
    "            # skip sims that fail to produce a spectrum\n",
    "            continue\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        if skip_first_xbin:\n",
    "            x = x[1:]\n",
    "            y = y[1:]\n",
    "        # sort by x ascending (so last entries are highest-k)\n",
    "        order = np.argsort(x)\n",
    "        x_sorted = x[order]\n",
    "        y_sorted = y[order]\n",
    "        n = len(x_sorted)\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        # keep only points with x>0 and y_sub>0 (required for log)\n",
    "        mask_pos = (x_sorted > 0) & (y_sorted > 0) & np.isfinite(y_sorted) & np.isfinite(x_sorted)\n",
    "\n",
    "        x_pos = x_sorted[mask_pos]\n",
    "        y_pos = y_sorted[mask_pos]\n",
    "\n",
    "        # log-log fit for slope b_i and intercept\n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "        # fit linear model ly = b * lx + intercept  (np.polyfit returns [b, intercept])\n",
    "        b_i, intercept = np.polyfit(lx, ly, 1)\n",
    "        log_a_i = intercept\n",
    "        a_i = float(np.exp(log_a_i))\n",
    "\n",
    "        # store\n",
    "        fit_cache[sid] = {\n",
    "            \"x\": x_sorted,\n",
    "            \"y\": y_sorted,\n",
    "            \"x_pos\": x_pos,\n",
    "            \"y_pos\": y_pos,\n",
    "            \"b\": float(b_i),\n",
    "            \"log_a\": float(log_a_i),\n",
    "            \"a\": a_i\n",
    "        }\n",
    "        # std of line of site velocities\n",
    "        try:\n",
    "            std_vlos = float(np.asarray(sim.vlos).std(ddof=ddof_std))\n",
    "        except Exception:\n",
    "            std_vlos = np.nan\n",
    "\n",
    "        rows.append({\"id\": sid, \"std_vlos\": std_vlos, \"b\": float(b_i), \"a\": a_i})\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        raise RuntimeError(\"No successful fits found (too few positive points after c-subtraction).\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 3) mean slope across sims\n",
    "    mean_b = float(df[\"b\"].mean())\n",
    "\n",
    "    # 4) Fix slope mean_b and recompute amplitude per sim (in log domain)\n",
    "    amplitudes = []\n",
    "    amp_errs = []\n",
    "    for sid in df[\"id\"].astype(str):\n",
    "        info = fit_cache[sid]\n",
    "        x_pos = info[\"x_pos\"]\n",
    "        y_pos = info[\"y_pos\"]\n",
    "        \n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "\n",
    "        p0_amp = [np.log(info.get('a', 1.0))]\n",
    "        popt_amp, pcov_amp = curve_fit(lambda x, a_prime: linear(x, mean_b, a_prime), lx, ly, p0=p0_amp, bounds=(-np.inf, np.inf), maxfev=20000)\n",
    "        a_hat = float(np.exp(popt_amp[0]))\n",
    "        if compute_amp_err and pcov_amp is not None:\n",
    "            perr = np.sqrt(np.diag(pcov_amp))\n",
    "            stderr_log_a = float(perr[0])               # std error on log(a)\n",
    "            amp_err = a_hat * stderr_log_a  \n",
    "\n",
    "        else:\n",
    "            amp_err = np.nan\n",
    "        \n",
    "        amplitudes.append(a_hat)\n",
    "        amp_errs.append(amp_err)\n",
    "\n",
    "    df[\"amplitude\"] = amplitudes\n",
    "    df[\"amp_err\"] = amp_errs\n",
    "\n",
    "    # Pearson correlation between std_vlos and amplitude\n",
    "    # require at least 2 valid points\n",
    "    mask_valid = np.isfinite(df[\"std_vlos\"]) & np.isfinite(df[\"amplitude\"])\n",
    "    if mask_valid.sum() >= 2:\n",
    "        r, pval = pearsonr(df.loc[mask_valid, \"std_vlos\"], df.loc[mask_valid, \"amplitude\"])\n",
    "    else:\n",
    "        r, pval = np.nan, np.nan\n",
    "\n",
    "    # Plot results: amplitude vs std_vlos with errorbars and linear fit line\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    xs = df[\"std_vlos\"].values\n",
    "    ys = df[\"amplitude\"].values\n",
    "    yerr = df[\"amp_err\"].values if \"amp_err\" in df.columns else None\n",
    "    ax.errorbar(xs, ys, yerr=yerr, fmt='o', capsize=3)\n",
    "    ax.set_xlabel(\"Std. Dev. of Line-of-Sight Velocity\")\n",
    "    ax.set_ylabel(\"Amplitude a (log-fit after c-subtraction)\")\n",
    "    ax.set_title(f\"Amplitude vs Std. Dev.  —  mean slope b = {mean_b:.3f}\\nPearson r={r:.3f}, p={pval:.3g}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # simple linear regression line for visualization (unweighted)\n",
    "    finite_mask = np.isfinite(xs) & np.isfinite(ys)\n",
    "    if finite_mask.sum() >= 2:\n",
    "        coeffs = np.polyfit(xs[finite_mask], ys[finite_mask], 1)\n",
    "        line_x = np.linspace(np.nanmin(xs[finite_mask]), np.nanmax(xs[finite_mask]), 200)\n",
    "        ax.plot(line_x, coeffs[0]*line_x + coeffs[1], label=f\"lin fit slope={coeffs[0]:.3g}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # annotate with ids (small offset)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.annotate(row[\"id\"], (row[\"std_vlos\"], row[\"amplitude\"]), textcoords=\"offset points\", xytext=(3,3), fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return df, mean_b, (r, pval), fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfed23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mean_b, (r,p), fig = analyze_simulations_power_law(simulations, simulations.keys())\n",
    "df.head(); print(\"mean slope b:\", mean_b, \"pearson r,p:\", (r,p))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c57ec",
   "metadata": {},
   "source": [
    "## Just High k's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136629ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_simulations_high_k(\n",
    "    simulations,\n",
    "    ids,\n",
    "    skip_first_xbin=True,\n",
    "    last_n_for_c: int = 10,\n",
    "    min_positive_points: int = 6,\n",
    "    ddof_std: int = 0,\n",
    "    compute_amp_err: bool = True,\n",
    "    k_cutoff: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "      simulations: dict-like mapping id (str/int) -> StellarStream object\n",
    "      ids: iterable of ids (strings or ints)\n",
    "      skip_first_xbin: whether to drop the first bin\n",
    "      last_n_for_c: how many last bins define the floor c\n",
    "      min_positive_points: minimum (#) positive points after subtracting c to attempt a fit\n",
    "      ddof_std: ddof for std_vlos\n",
    "      compute_amp_err: whether to estimate an error on amplitude (simple standard error in log domain)\n",
    "      k_cutoff: the percent of k values to include starting from high to low (0.1 includes the highest 10% etc)\n",
    "\n",
    "    Returns:\n",
    "      df, mean_slope, (pearson_r, pearson_p), fig\n",
    "    \"\"\"\n",
    "    ids_list = [str(i) for i in list(ids)]\n",
    "    rows = []\n",
    "    fit_cache = {}  # store x,y,c,y_sub,b,a,log_a for each successful sim\n",
    "\n",
    "    for sid in ids_list:\n",
    "        if sid not in simulations:\n",
    "            # skip missing sims quietly\n",
    "            continue\n",
    "        sim = simulations[sid]\n",
    "        try:\n",
    "            x, y = sim.power_spectrum(precision=1.0, detrend='linear')\n",
    "        except Exception:\n",
    "            # skip sims that fail to produce a spectrum\n",
    "            continue\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        if skip_first_xbin:\n",
    "            x = x[1:]\n",
    "            y = y[1:]\n",
    "        # sort by x ascending (so last entries are highest-k)\n",
    "        order = np.argsort(x)\n",
    "        x_sorted = x[order]\n",
    "        y_sorted = y[order]\n",
    "        n = len(x_sorted)\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        # estimate c as mean of last_n_for_c y-values (highest-k)\n",
    "        last_n = min(last_n_for_c, n)\n",
    "        c_est = float(np.mean(y_sorted[-last_n:]))\n",
    "\n",
    "        # subtract c\n",
    "        y_sub = y_sorted - c_est\n",
    "\n",
    "        # k Cutoff\n",
    "        k_index = int(n * k_cutoff)\n",
    "        x_sorted = x_sorted[:k_index]\n",
    "        y_sub = y_sub[:k_index]\n",
    "\n",
    "        # keep only points with x>0 and y_sub>0 (required for log)\n",
    "        mask_pos = (x_sorted > 0) & (y_sub > 0) & np.isfinite(y_sub) & np.isfinite(x_sorted)\n",
    "        if np.sum(mask_pos) < min_positive_points:\n",
    "            # skip if too few usable bins after subtraction\n",
    "            continue\n",
    "\n",
    "        x_pos = x_sorted[mask_pos]\n",
    "        y_pos = y_sub[mask_pos]\n",
    "\n",
    "        # log-log fit for slope b_i and intercept\n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "        # fit linear model ly = b * lx + intercept  (np.polyfit returns [b, intercept])\n",
    "        b_i, intercept = np.polyfit(lx, ly, 1)\n",
    "        log_a_i = intercept\n",
    "        a_i = float(np.exp(log_a_i))\n",
    "\n",
    "        # store\n",
    "        fit_cache[sid] = {\n",
    "            \"x\": x_sorted,\n",
    "            \"y\": y_sorted,\n",
    "            \"c_est\": c_est,\n",
    "            \"x_pos\": x_pos,\n",
    "            \"y_pos\": y_pos,\n",
    "            \"b\": float(b_i),\n",
    "            \"log_a\": float(log_a_i),\n",
    "            \"a\": a_i\n",
    "        }\n",
    "        # std of line of site velocities\n",
    "        try:\n",
    "            std_vlos = float(np.asarray(sim.vlos).std(ddof=ddof_std))\n",
    "        except Exception:\n",
    "            std_vlos = np.nan\n",
    "\n",
    "        rows.append({\"id\": sid, \"std_vlos\": std_vlos, \"b\": float(b_i), \"a\": a_i, \"c_est\": c_est})\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        raise RuntimeError(\"No successful fits found (too few positive points after c-subtraction).\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 3) mean slope across sims\n",
    "    mean_b = float(df[\"b\"].mean())\n",
    "\n",
    "    # 4) Fix slope mean_b and recompute amplitude per sim (in log domain)\n",
    "    amplitudes = []\n",
    "    amp_errs = []\n",
    "    for sid in df[\"id\"].astype(str):\n",
    "        info = fit_cache[sid]\n",
    "        x_pos = info[\"x_pos\"]\n",
    "        y_pos = info[\"y_pos\"]\n",
    "        \n",
    "        lx = np.log(x_pos)\n",
    "        ly = np.log(y_pos)\n",
    "\n",
    "        p0_amp = [np.log(info.get('a', 1.0))]\n",
    "        popt_amp, pcov_amp = curve_fit(lambda x, a_prime: linear(x, mean_b, a_prime), lx, ly, p0=p0_amp, bounds=(-np.inf, np.inf), maxfev=20000)\n",
    "        a_hat = float(np.exp(popt_amp[0]))\n",
    "        if compute_amp_err and pcov_amp is not None:\n",
    "            perr = np.sqrt(np.diag(pcov_amp))\n",
    "            stderr_log_a = float(perr[0])               # std error on log(a)\n",
    "            amp_err = a_hat * stderr_log_a  \n",
    "\n",
    "        else:\n",
    "            amp_err = np.nan\n",
    "        \n",
    "        amplitudes.append(a_hat)\n",
    "        amp_errs.append(amp_err)\n",
    "\n",
    "    df[\"amplitude\"] = amplitudes\n",
    "    df[\"amp_err\"] = amp_errs\n",
    "\n",
    "    # Pearson correlation between std_vlos and amplitude\n",
    "    # require at least 2 valid points\n",
    "    mask_valid = np.isfinite(df[\"std_vlos\"]) & np.isfinite(df[\"amplitude\"])\n",
    "    if mask_valid.sum() >= 2:\n",
    "        r, pval = pearsonr(df.loc[mask_valid, \"std_vlos\"], df.loc[mask_valid, \"amplitude\"])\n",
    "    else:\n",
    "        r, pval = np.nan, np.nan\n",
    "\n",
    "    # Plot results: amplitude vs std_vlos with errorbars and linear fit line\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    xs = df[\"std_vlos\"].values\n",
    "    ys = df[\"amplitude\"].values\n",
    "    yerr = df[\"amp_err\"].values if \"amp_err\" in df.columns else None\n",
    "    ax.errorbar(xs, ys, yerr=yerr, fmt='o', capsize=3)\n",
    "    ax.set_xlabel(\"Std. Dev. of Line-of-Sight Velocity\")\n",
    "    ax.set_ylabel(\"Amplitude a (log-fit after c-subtraction)\")\n",
    "    ax.set_title(f\"Amplitude vs Std. Dev.  —  mean slope b = {mean_b:.3f}\\nPearson r={r:.3f}, p={pval:.3g}\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # simple linear regression line for visualization (unweighted)\n",
    "    finite_mask = np.isfinite(xs) & np.isfinite(ys)\n",
    "    if finite_mask.sum() >= 2:\n",
    "        coeffs = np.polyfit(xs[finite_mask], ys[finite_mask], 1)\n",
    "        line_x = np.linspace(np.nanmin(xs[finite_mask]), np.nanmax(xs[finite_mask]), 200)\n",
    "        ax.plot(line_x, coeffs[0]*line_x + coeffs[1], label=f\"lin fit slope={coeffs[0]:.3g}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # annotate with ids (small offset)\n",
    "    for _, row in df.iterrows():\n",
    "        ax.annotate(row[\"id\"], (row[\"std_vlos\"], row[\"amplitude\"]), textcoords=\"offset points\", xytext=(3,3), fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return df, mean_b, (r, pval), fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, mean_b, (r,p), fig = analyze_simulations_high_k(simulations, simulations.keys(), k_cutoff=0.4)\n",
    "df.head(); print(\"mean slope b:\", mean_b, \"pearson r,p:\", (r,p))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
