{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "from astroML.correlation import two_point\n",
    "\n",
    "from stellar_stream import StellarStream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50000\n",
    "mu, phi2_sigma = 0, 1 # mean and standard deviation\n",
    "vlos_sigma = 5\n",
    "rng = np.random.default_rng(seed=42)\n",
    "phi1 = rng.uniform(-180, 180, size)\n",
    "phi2 = rng.normal(mu, phi2_sigma, size)\n",
    "vlos = rng.normal(mu, vlos_sigma, size)\n",
    "\n",
    "\n",
    "def wiggle(location, amplitude, width):\n",
    "    return amplitude * np.exp(-0.5*((phi1-location)/width)**2)\n",
    "\n",
    "\n",
    "\n",
    "def gap(phi1, phi2, vlos, gap_center, gap_depth, gap_width):\n",
    "    prob_keep = 1.0 - gap_depth * np.exp(-0.5 * ((phi1 - gap_center)/gap_width)**2)\n",
    "    mask = np.random.rand(len(phi1)) < prob_keep\n",
    "    return phi1[mask], phi2[mask], vlos[mask]\n",
    "\n",
    "\n",
    "\n",
    "def add_substructure(phi1, phi2, vlos, scale, amount):\n",
    "    phi1_copy, phi2_copy, vlos_copy = phi1.copy(), phi2.copy(), vlos.copy()\n",
    "    for i in range(amount):\n",
    "        location = rng.uniform(min(phi1), max(phi1), 1)\n",
    "        depth = rng.uniform(0.1, 1, 1)\n",
    "        width = rng.lognormal(mean=np.log(scale), sigma=0.3)\n",
    "        phi1_copy, phi2_copy, vlos_copy = gap(phi1_copy, phi2_copy, vlos_copy, location, depth, width)\n",
    "    return phi1_copy, phi2_copy, vlos_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_substructure(phi1, phi2=None, vlos=None,\n",
    "                        amount=1, scale=0.5,  # typical width scale (same units as phi1)\n",
    "                        mode=\"point\",         # \"point\" or \"binned\"\n",
    "                        kind=\"gaussian\",      # currently only gaussian supported\n",
    "                        depths=None,          # array-like or scalar: depletion fraction (0..1) for gaps OR amplitude for overdensity\n",
    "                        amps=None,            # for overdensity amplitude (multiplicative)\n",
    "                        rng=None,\n",
    "                        binned_kwargs=None):\n",
    "    \"\"\"\n",
    "    Inject `amount` substructures into a stream along phi1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phi1 : 1D array\n",
    "        along-stream coordinate of points (assumed in same units as `scale`).\n",
    "    phi2 : 1D array or None\n",
    "        across-stream coordinate (will be carried through unchanged except for duplication/removal).\n",
    "    vlos : 1D array or None\n",
    "        velocities (carried through).\n",
    "    amount : int\n",
    "        number of features to inject.\n",
    "    scale : float\n",
    "        nominal width (sigma) for gaussian perturbations (same units as phi1).\n",
    "    mode : {\"point\",\"binned\"}\n",
    "        - \"point\": modify the point catalog by probabilistic removal (gaps) or Poisson duplications (overdensities).\n",
    "        - \"binned\": expects binned_kwargs dict with keys (bins, density) and returns modified density.\n",
    "    depths : scalar or array-like\n",
    "        For gaps: fraction removed at center (0..1). If None, uniform random in [0.1,1.0].\n",
    "    amps : scalar or array-like\n",
    "        For overdensities: fractional amplitude (e.g. 0.5 means +50% at center). If None, drawn from Uniform(0.1,1.0).\n",
    "    rng : np.random.Generator or None\n",
    "        RNG for reproducibility. If None, uses np.random.default_rng().\n",
    "    binned_kwargs : dict\n",
    "        Required if mode == \"binned\". Should contain 'bins' (edges) and 'density' (array).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If mode == \"point\":\n",
    "      phi1_new, phi2_new, vlos_new, injected_params\n",
    "    If mode == \"binned\":\n",
    "      density_new, injected_params\n",
    "\n",
    "    injected_params: list of dicts {kind, center, sigma, depth/amp}\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    phi1 = np.asarray(phi1)\n",
    "    N = len(phi1)\n",
    "    has_phi2 = phi2 is not None\n",
    "    has_vlos = vlos is not None\n",
    "    if has_phi2:\n",
    "        phi2 = np.asarray(phi2)\n",
    "    if has_vlos:\n",
    "        vlos = np.asarray(vlos)\n",
    "\n",
    "    # Helpers to draw parameters\n",
    "    def draw_centers(n):\n",
    "        return rng.uniform(phi1.min(), phi1.max(), size=n)\n",
    "\n",
    "    def draw_depths(n):\n",
    "        if depths is None:\n",
    "            return rng.uniform(0.1, 1.0, size=n)\n",
    "        d = np.asarray(depths)\n",
    "        return np.broadcast_to(d, (n,)) if d.size == 1 else d\n",
    "\n",
    "    def draw_amps(n):\n",
    "        if amps is None:\n",
    "            return rng.uniform(0.1, 1.0, size=n)\n",
    "        a = np.asarray(amps)\n",
    "        return np.broadcast_to(a, (n,)) if a.size == 1 else a\n",
    "\n",
    "    centers = draw_centers(amount)\n",
    "    sigmas = rng.lognormal(mean=np.log(scale), sigma=0.3, size=amount)  # lognormal scatter\n",
    "    depths_arr = draw_depths(amount)\n",
    "    amps_arr = draw_amps(amount)\n",
    "\n",
    "    injected = []\n",
    "\n",
    "    if mode == \"binned\":\n",
    "        # binned approach: apply multiplicative factors to provided density\n",
    "        assert binned_kwargs is not None, \"binned_kwargs required for mode='binned'.\"\n",
    "        bins = np.asarray(binned_kwargs[\"bins\"])\n",
    "        density = np.asarray(binned_kwargs[\"density\"]).astype(float)\n",
    "        xcenters = 0.5 * (bins[:-1] + bins[1:])\n",
    "        density_new = density.copy()\n",
    "        for i in range(amount):\n",
    "            c = centers[i]\n",
    "            sigma = sigmas[i]\n",
    "            if binned_kwargs.get(\"type\", \"gap\") == \"gap\":\n",
    "                depth = depths_arr[i]\n",
    "                factor = 1.0 - depth * np.exp(-0.5 * ((xcenters - c)/sigma)**2)\n",
    "            else:\n",
    "                amp = amps_arr[i]\n",
    "                factor = 1.0 + amp * np.exp(-0.5 * ((xcenters - c)/sigma)**2)\n",
    "            density_new *= factor  # multiplicative modulation\n",
    "            injected.append(dict(kind=binned_kwargs.get(\"type\",\"gap\"), center=float(c),\n",
    "                                 sigma=float(sigma),\n",
    "                                 depth=float(depths_arr[i]) if binned_kwargs.get(\"type\",\"gap\") else None,\n",
    "                                 amp=float(amps_arr[i]) if not binned_kwargs.get(\"type\",\"gap\") else None))\n",
    "        return density_new, injected\n",
    "\n",
    "    # MODE == \"point\" (operate on catalogs)\n",
    "    # We'll apply sequentially: for gaps we probabilistically remove points, for overdensities duplicate points with Poisson draws.\n",
    "    phi1_work = phi1.copy()\n",
    "    phi2_work = phi2.copy() if has_phi2 else None\n",
    "    vlos_work = vlos.copy() if has_vlos else None\n",
    "\n",
    "    for i in range(amount):\n",
    "        c = centers[i]\n",
    "        sigma = sigmas[i]\n",
    "        depth = depths_arr[i]\n",
    "        amp = amps_arr[i]\n",
    "\n",
    "        # Gaussian profile (value from 0..1)\n",
    "        # For a gap (underdensity): keep_prob = 1 - depth * exp(...)\n",
    "        # For an overdensity: extra_expectation = amp * exp(...)\n",
    "        g = np.exp(-0.5 * ((phi1_work - c)/sigma)**2)\n",
    "\n",
    "        # --- gap (probabilistic removal) ---\n",
    "        # compute keep probability per star\n",
    "        keep_prob = 1.0 - depth * g\n",
    "        # safety clamp to [0,1]\n",
    "        keep_prob = np.clip(keep_prob, 0.0, 1.0)\n",
    "\n",
    "        # sample uniform to decide which stars to keep\n",
    "        u = rng.random(size=keep_prob.size)\n",
    "        keep_mask = (u < keep_prob)\n",
    "\n",
    "        # apply removal\n",
    "        phi1_work = phi1_work[keep_mask]\n",
    "        if has_phi2:\n",
    "            phi2_work = phi2_work[keep_mask]\n",
    "        if has_vlos:\n",
    "            vlos_work = vlos_work[keep_mask]\n",
    "\n",
    "        # --- overdensity (Poisson duplication) ---\n",
    "        # For overdensity we add additional stars: for each remaining star, expected extra count = amp * g\n",
    "        # Draw k ~ Poisson(amp * g) and duplicate point k times.\n",
    "        # Note: we only apply overdensity in addition to gap if amp>0\n",
    "        if amp > 1e-12:\n",
    "            # recompute g on current catalog (after the gap)\n",
    "            g2 = np.exp(-0.5 * ((phi1_work - c)/sigma)**2)\n",
    "            lam = amp * g2  # expected extra count per star (can be <1)\n",
    "            # draw Poisson for each star\n",
    "            extra_counts = rng.poisson(lam)\n",
    "            if extra_counts.sum() > 0:\n",
    "                # indices with extra\n",
    "                idx_extra = np.nonzero(extra_counts)[0]\n",
    "                # build arrays to append\n",
    "                phi1_extra = np.repeat(phi1_work[idx_extra], extra_counts[idx_extra])\n",
    "                if has_phi2:\n",
    "                    phi2_extra = np.repeat(phi2_work[idx_extra], extra_counts[idx_extra])\n",
    "                if has_vlos:\n",
    "                    vlos_extra = np.repeat(vlos_work[idx_extra], extra_counts[idx_extra])\n",
    "                # append extras\n",
    "                phi1_work = np.concatenate([phi1_work, phi1_extra])\n",
    "                if has_phi2:\n",
    "                    phi2_work = np.concatenate([phi2_work, phi2_extra])\n",
    "                if has_vlos:\n",
    "                    vlos_work = np.concatenate([vlos_work, vlos_extra])\n",
    "\n",
    "        injected.append(dict(kind=\"gaussian_gap_plus_over\", center=float(c),\n",
    "                             sigma=float(sigma),\n",
    "                             depth=float(depth),\n",
    "                             amp=float(amp)))\n",
    "    # final: optionally shuffle to avoid sorted blocks\n",
    "    order = rng.permutation(len(phi1_work))\n",
    "    phi1_new = phi1_work[order]\n",
    "    phi2_new = phi2_work[order] if has_phi2 else None\n",
    "    vlos_new = vlos_work[order] if has_vlos else None\n",
    "\n",
    "    return phi1_new, phi2_new, vlos_new, injected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696434a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b04a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50000\n",
    "mu, phi2_sigma = 0, 1 # mean and standard deviation\n",
    "vlos_sigma = 5\n",
    "rng = np.random.default_rng()\n",
    "phi1 = rng.uniform(-300, 300, size)\n",
    "phi2 = rng.normal(mu, phi2_sigma, size)\n",
    "vlos = rng.normal(mu, vlos_sigma, size)\n",
    "\n",
    "amount = 4\n",
    "phi1_low, phi2_low, vlos_low, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=100, scale=100)\n",
    "phi1_mid, phi2_mid, vlos_mid, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=100, scale=10)\n",
    "phi1_high, phi2_high, vlos_high, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=100, scale=1)\n",
    "\n",
    "\n",
    "S_low = (StellarStream.from_catalog(phi1_low, phi2_low, vlos_low, 'low stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=6.0))\n",
    "\n",
    "\n",
    "S_mid = (StellarStream.from_catalog(phi1_mid, phi2_mid, vlos_mid, 'mid stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=6.0))\n",
    "\n",
    "\n",
    "S_high = (StellarStream.from_catalog(phi1_high, phi2_high, vlos_high, 'high stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=6.0))\n",
    "\n",
    "S = (StellarStream.from_catalog(phi1, phi2, vlos, 'base stream'))\n",
    "          # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "          # .select(\"restrict_phi2\", phi2_lim=6.0))\n",
    "\n",
    "\n",
    "\n",
    "S_low.plot_stream()\n",
    "S_mid.plot_stream()\n",
    "S_high.select(\"restrict_phi1\", phi1_lim=(-100, 0)).plot_stream()\n",
    "plt.show()\n",
    "\n",
    "# bins_low, results_low = substructures(*S_low.density_phi1())\n",
    "# bins_mid, results_mid = substructures(*S_mid.density_phi1())\n",
    "# bins_high, results_high = substructures(*S_high.density_phi1())\n",
    "# plt.plot(bins_low, results_low, label='low freq')\n",
    "# plt.plot(bins_mid, results_mid, label='mid freq')\n",
    "# plt.plot(bins_high, results_high, label='high freq')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "StellarStream.plot_power_spectrum_denoised(S_low, S_mid, S_high, S, precision=0.2)\n",
    "StellarStream.plot_power_spectrum(S_low, S_mid, S_high, S, precision=0.2, window='hann')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2964108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def substructures_1(bins: npt.NDArray, dens: npt.NDArray) -> npt.NDArray:\n",
    "    widths = np.diff(bins)\n",
    "    bin_width = widths[0]  # uniform because linspace\n",
    "\n",
    "    bins = []\n",
    "    results = []\n",
    "    for i in range(1, 300):\n",
    "        sigma_bins = float(i/100) / bin_width\n",
    "        bins.append(sigma_bins * bin_width)\n",
    "        dens_new = gaussian_filter1d(dens, sigma=sigma_bins)\n",
    "        results.append(simpson(np.abs(dens_new - dens)))\n",
    "        dens = dens_new\n",
    "        \n",
    "    bins = np.array(bins)\n",
    "    results = np.array(results)/simpson(results, x=bins)  # Normalize by the maximum frequency\n",
    "    return bins, results\n",
    "\n",
    "def substructures_2(bins: npt.NDArray, dens: npt.NDArray) -> npt.NDArray:\n",
    "    widths = np.diff(bins)\n",
    "    bin_width = widths[0]  # uniform because linspace\n",
    "\n",
    "    bins = []\n",
    "    results = []\n",
    "    for i in range(1, 300):\n",
    "        sigma_bins = float(i/100) / bin_width\n",
    "        bins.append(sigma_bins * bin_width)\n",
    "        dens_new = gaussian_filter1d(dens, sigma=sigma_bins)\n",
    "        results.append(simpson(np.abs(dens_new - dens)))\n",
    "        \n",
    "    bins = np.array(bins)[:-1]\n",
    "    results = np.diff(np.array(results))\n",
    "    \n",
    "    return bins, results/simpson(results, x=bins)  # Normalize\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def fourier_substructures(bins: np.ndarray, dens: np.ndarray):\n",
    "    \"\"\"\n",
    "    Decompose a signal into substructure strength at each scale using Fourier analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bins : np.ndarray\n",
    "        The x-axis values (uniform spacing assumed).\n",
    "    dens : np.ndarray\n",
    "        The density values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    freqs : np.ndarray\n",
    "        The Fourier frequencies (cycles per unit of bins).\n",
    "    power_norm : np.ndarray\n",
    "        The normalized power spectrum (substructure strength per scale).\n",
    "    \"\"\"\n",
    "    # Uniform bin spacing\n",
    "    dx = bins[1] - bins[0]\n",
    "    \n",
    "    # FFT of the signal\n",
    "    fft_vals = np.fft.rfft(dens - np.mean(dens))  # remove mean to ignore DC component\n",
    "    power = np.abs(fft_vals)**2  # power spectrum\n",
    "    \n",
    "    # Corresponding frequencies (cycles per unit length)\n",
    "    freqs = np.fft.rfftfreq(len(dens), d=dx)\n",
    "    \n",
    "    # Normalize so the integral over frequency is 1\n",
    "    norm = np.trapz(power, freqs)\n",
    "    power_norm = power / norm if norm > 0 else power\n",
    "    \n",
    "    return freqs, power_norm\n",
    "\n",
    "\n",
    "\n",
    "# bins_1, results_1 = substructures_1(*S_high.density_phi1())\n",
    "# bins_2, results_2 = substructures_2(*S_high.density_phi1())\n",
    "\n",
    "bins, results = substructures_2(*S.density_phi1())\n",
    "bins_low, results_low = substructures_2(*S_low.density_phi1())\n",
    "bins_mid, results_mid = substructures_2(*S_mid.density_phi1())\n",
    "bins_high, results_high = substructures_2(*S_high.density_phi1())\n",
    "\n",
    "# plt.plot(bins_1, results_1, label='1')\n",
    "# plt.plot(bins_2, results_2, label='2')\n",
    "\n",
    "plt.plot(bins_low, results_low, label='low freq')\n",
    "plt.plot(bins_mid, results_mid, label='mid freq')\n",
    "plt.plot(bins_high, results_high, label='high freq')\n",
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "print(f\"low mean: {np.mean(results_low)}\")\n",
    "print(f\"mid mean: {np.mean(results_mid)}\")\n",
    "print(f\"high mean: {np.mean(results_high)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8423d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, freq_high, ps_high = compute_power_spectrum(phi1_high)\n",
    "_, _, freq_mid, ps_mid = compute_power_spectrum(phi1_mid)\n",
    "_, _, freq_low, ps_low = compute_power_spectrum(phi1_low)\n",
    "\n",
    "plt.plot(freq_high[1:], ps_high[1:])\n",
    "plt.plot(freq_mid[1:], ps_mid[1:])\n",
    "plt.plot(freq_low[1:], ps_low[1:])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7aa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50000\n",
    "mu, phi2_sigma = 0, 1 # mean and standard deviation\n",
    "vlos_sigma = 5\n",
    "rng = np.random.default_rng(seed=42)\n",
    "phi1 = rng.uniform(-180, 180, size)\n",
    "phi2 = rng.normal(mu, phi2_sigma, size)\n",
    "vlos = rng.normal(mu, vlos_sigma, size)\n",
    "\n",
    "amount = 4\n",
    "phi1_low, phi2_low, vlos_low, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=50, scale=1e-1)\n",
    "phi1_mid, phi2_mid, vlos_mid, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=50, scale=1e0)\n",
    "phi1_high, phi2_high, vlos_high, _ = inject_substructure(phi1, phi2=phi2, vlos=vlos, amount=50, scale=1e1)\n",
    "\n",
    "tile = 10\n",
    "view = 360\n",
    "add_low = np.concatenate([np.repeat(i * 360, len(phi1_low)) for i in range(tile)])\n",
    "phi1_low, phi2_low, vlos_low = np.tile(phi1_low, (tile,)) + add_low, np.tile(phi2_low, (tile,)), np.tile(vlos_low, (tile,))\n",
    "\n",
    "add_mid = np.concatenate([np.repeat(i * 360, len(phi1_mid)) for i in range(tile)])\n",
    "phi1_mid, phi2_mid, vlos_mid = np.tile(phi1_mid, (tile,)) + add_mid, np.tile(phi2_mid, (tile,)), np.tile(vlos_mid, (tile,))\n",
    "\n",
    "add_high = np.concatenate([np.repeat(i * 360, len(phi1_high)) for i in range(tile)])\n",
    "phi1_high, phi2_high, vlos_high = np.tile(phi1_high, (tile,)) + add_high, np.tile(phi2_high, (tile,)), np.tile(vlos_high, (tile,))\n",
    "\n",
    "\n",
    "S_low = (StellarStream.from_catalog(phi1_low, phi2_low, vlos_low, 'low stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "\n",
    "S_mid = (StellarStream.from_catalog(phi1_mid, phi2_mid, vlos_mid, 'mid stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "\n",
    "S_high = (StellarStream.from_catalog(phi1_high, phi2_high, vlos_high, 'high stream'))\n",
    "     # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "     # .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "S = (StellarStream.from_catalog(phi1, phi2, vlos, 'base stream'))\n",
    "          # .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "          # .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "\n",
    "\n",
    "S_low.plot_stream()\n",
    "S_mid.plot_stream()\n",
    "S_high.plot_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60089296",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, norm_dens = S.density_phi1(smooth=True, interpolate=True, precision=1)\n",
    "_, high_dens = S_high.density_phi1(smooth=True, interpolate=True, precision=1)\n",
    "_, mid_dens = S_mid.density_phi1(smooth=True, interpolate=True, precision=1)\n",
    "_, low_dens = S_low.density_phi1(smooth=True, interpolate=True, precision=1)\n",
    "\n",
    "diff_high = np.abs(norm_dens - high_dens)\n",
    "diff_mid = np.abs(norm_dens - mid_dens)\n",
    "diff_low = np.abs(norm_dens - low_dens)\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "plt.scatter(bins, diff_high, label='High Density Difference')\n",
    "plt.scatter(bins, diff_mid, label='Mid Density Difference')\n",
    "plt.scatter(bins, diff_low, label='Low Density Difference')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, freqs = S.power_spectrum(smooth=True, interpolate=True, precision=1)\n",
    "_, low_freq = S_low.power_spectrum(smooth=True, interpolate=True, precision=1)\n",
    "_, mid_freq = S_mid.power_spectrum(smooth=True, interpolate=True, precision=1)\n",
    "_, high_freqs = S_high.power_spectrum(smooth=True, interpolate=True, precision=1)\n",
    "\n",
    "\n",
    "# bins, freqs = S.power_spectrum()\n",
    "# _, low_freq = S_low.power_spectrum()\n",
    "# _, mid_freq = S_mid.power_spectrum()\n",
    "# _, high_freqs = S_high.power_spectrum()\n",
    "\n",
    "mask = (bins > 0)\n",
    "\n",
    "diff_high = np.abs(freqs - high_freqs)\n",
    "diff_high_normalized = diff_high / simpson(diff_high, x=bins)  # Normalize by the maximum frequency\n",
    "diff_low = np.abs(freqs - low_freq)\n",
    "diff_low_normalized = diff_low / simpson(diff_low, x=bins)  # Normalize by the maximum frequency\n",
    "diff_mid = np.abs(freqs - mid_freq)\n",
    "diff_mid_normalized = diff_mid / simpson(diff_mid, x=bins)  # Normalize by the maximum frequency\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "plt.plot(bins[mask], diff_high_normalized[mask], label='High Frequency Difference')\n",
    "plt.plot(bins[mask], diff_low_normalized[mask], label='Low Frequency Difference')\n",
    "plt.plot(bins[mask], diff_mid_normalized[mask], label='Mid Frequency Difference')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(10**-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import rfft, rfftfreq\n",
    "from scipy.signal import get_window, welch\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "def power_spectrum_denoised(\n",
    "    phi1: ArrayLike,\n",
    "    y: ArrayLike,\n",
    "    *,\n",
    "    grid_ddeg: float = 0.1,          # uniform bin width in degrees\n",
    "    detrend: str = \"poly3\",          # \"none\"|\"poly2\"|\"poly3\"\n",
    "    window: str = \"tukey\",           # \"tukey\"|\"hann\"\n",
    "    tukey_alpha: float = 0.25,\n",
    "    method: str = \"welch\",           # \"welch\"|\"fft\"|\"lomb\" (lomb not shown here)\n",
    "    n_segments: int = 6,             # Welch: 4–8 is typical for ~100°\n",
    "    overlap: float = 0.5,            # 50% overlap\n",
    "    median_average: bool = True,     # median Welch\n",
    "    subtract_highk_floor: bool = True,\n",
    "    return_errors: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        f_cpd : frequencies [cycles/degree]\n",
    "        ps    : one-sided PSD with energy-preserving normalization\n",
    "        err   : jackknife error (if return_errors=True), else None\n",
    "    \"\"\"\n",
    "    phi1 = np.asarray(phi1)\n",
    "    y    = np.asarray(y)\n",
    "\n",
    "    # 1) Uniform grid (inverse-variance weighting optional)\n",
    "    phi_min, phi_max = np.min(phi1), np.max(phi1)\n",
    "    edges = np.arange(phi_min, phi_max + grid_ddeg, grid_ddeg)\n",
    "    centers = 0.5*(edges[1:] + edges[:-1])\n",
    "    # simple binning:\n",
    "    idx = np.digitize(phi1, edges) - 1\n",
    "    mask = (idx >= 0) & (idx < len(centers))\n",
    "    bsum = np.bincount(idx[mask], weights=y[mask], minlength=len(centers))\n",
    "    bcnt = np.bincount(idx[mask], minlength=len(centers))\n",
    "    dens = np.zeros_like(centers)\n",
    "    nz = bcnt > 0\n",
    "    dens[nz] = bsum[nz] / bcnt[nz]\n",
    "    # fill small gaps by linear interp (optional):\n",
    "    if np.any(~nz):\n",
    "        dens = np.interp(centers, centers[nz], dens[nz])\n",
    "\n",
    "    # normalize to mean 1 (optional but common for density)\n",
    "    dens /= np.mean(dens)\n",
    "\n",
    "    # 2) Detrend\n",
    "    if detrend == \"poly2\":\n",
    "        X = np.vstack([np.ones_like(centers), centers, centers**2]).T\n",
    "        beta = np.linalg.lstsq(X, dens, rcond=None)[0]\n",
    "        trend = X @ beta\n",
    "        resid = dens - trend\n",
    "    elif detrend == \"poly3\":\n",
    "        X = np.vstack([np.ones_like(centers), centers, centers**2, centers**3]).T\n",
    "        beta = np.linalg.lstsq(X, dens, rcond=None)[0]\n",
    "        trend = X @ beta\n",
    "        resid = dens - trend\n",
    "    else:\n",
    "        resid = dens - np.mean(dens)\n",
    "\n",
    "    # 3) Window (apodize)\n",
    "    if window == \"tukey\":\n",
    "        w = get_window((\"tukey\", tukey_alpha), len(resid), fftbins=True)\n",
    "    else:\n",
    "        w = get_window(\"hann\", len(resid), fftbins=True)\n",
    "    x = resid * w\n",
    "\n",
    "    # 4) PSD\n",
    "    dphi = grid_ddeg  # sampling in degrees\n",
    "    if method == \"fft\":\n",
    "        # one-sided periodogram with energy-preserving normalization\n",
    "        n = len(x)\n",
    "        X = rfft(x)\n",
    "        f = rfftfreq(n, d=dphi)  # cycles per degree\n",
    "        ps = (2.0 * (np.abs(X)**2) * dphi / (n))  # one-sided; factor 2 except DC/Nyquist handled by rfft\n",
    "        # fix DC/Nyquist normalization\n",
    "        ps[0] /= 2.0\n",
    "        if n % 2 == 0:\n",
    "            ps[-1] /= 2.0\n",
    "        spectra = None\n",
    "    else:\n",
    "        # Welch with robust (median) combine\n",
    "        nperseg = int(np.floor(len(x) / (1 + (1-overlap) * (n_segments-1))))\n",
    "        nperseg = max(nperseg, 32)\n",
    "        noverlap = int(overlap * nperseg)\n",
    "        f, ps_w = welch(\n",
    "            x, fs=1.0/dphi, window=window if window!=\"tukey\" else (\"tukey\", tukey_alpha),\n",
    "            nperseg=nperseg, noverlap=noverlap, detrend=False, return_onesided=True, scaling=\"density\"\n",
    "        )\n",
    "        # welch(scaling=\"density\") already returns energy-preserving (power per cpd)\n",
    "        ps = ps_w\n",
    "        spectra = None  # for simple jackknife we’ll re-run internally on segments if needed\n",
    "\n",
    "    # 5) Subtract white-noise floor (empirical)\n",
    "    if subtract_highk_floor:\n",
    "        hi = f > 0.7*np.max(f)  # top 30% of band\n",
    "        if np.any(hi):\n",
    "            floor = np.median(ps[hi])\n",
    "            ps = np.clip(ps - floor, a_min=0.0, a_max=None)\n",
    "\n",
    "    # 6) Jackknife errors over Welch segments (quick approximation)\n",
    "    err = None\n",
    "    if return_errors and method == \"welch\":\n",
    "        # redo Welch but extract segment spectra and jackknife\n",
    "        # (simple approximation: split into K blocks without overlap for DOF)\n",
    "        K = max(4, n_segments//1)\n",
    "        seg_len = len(x)//K\n",
    "        seg_ps = []\n",
    "        for k in range(K):\n",
    "            seg = x[k*seg_len:(k+1)*seg_len]\n",
    "            if len(seg) < 32: continue\n",
    "            fk, Pk = welch(\n",
    "                seg, fs=1.0/dphi, window=window if window!=\"tukey\" else (\"tukey\", tukey_alpha),\n",
    "                nperseg=min(len(seg), nperseg), noverlap=0, detrend=False, return_onesided=True, scaling=\"density\"\n",
    "            )\n",
    "            seg_ps.append(Pk)\n",
    "        if len(seg_ps) >= 2:\n",
    "            seg_ps = np.array(seg_ps)\n",
    "            # match frequency grid\n",
    "            if fk.shape == f.shape:\n",
    "                mu = np.mean(seg_ps, axis=0)\n",
    "                jk = []\n",
    "                for i in range(len(seg_ps)):\n",
    "                    mu_i = np.mean(np.delete(seg_ps, i, axis=0), axis=0)\n",
    "                    jk.append(mu_i)\n",
    "                jk = np.array(jk)\n",
    "                # jackknife variance\n",
    "                err = np.sqrt((len(seg_ps)-1) * np.mean((jk - mu)**2, axis=0))\n",
    "            else:\n",
    "                err = None\n",
    "\n",
    "    return f, ps, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_low, ps_low, err_low = power_spectrum_denoised(phi1_low, phi2_low)\n",
    "freq_mid, ps_mid, err_mid = power_spectrum_denoised(phi1_mid, phi2_mid)\n",
    "freq_high, ps_high, err_high = power_spectrum_denoised(phi1_high, phi2_high)\n",
    "\n",
    "plt.plot(freq_low[1:], ps_low[1:], label='low freq', alpha=0.7)\n",
    "plt.plot(freq_mid[1:], ps_mid[1:], label='mid freq', alpha=0.7)\n",
    "plt.plot(freq_high[1:], ps_high[1:], label='high freq', alpha=0.7)   \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "on = True\n",
    "freq_low, ps_low, err_low = power_spectrum_denoised(*S_low.density_phi1(smooth=on, interpolate=on, precision=1))\n",
    "freq_mid, ps_mid, err_mid = power_spectrum_denoised(*S_mid.density_phi1(smooth=on, interpolate=on, precision=1))\n",
    "freq_high, ps_high, err_high = power_spectrum_denoised(*S_high.density_phi1(smooth=on, interpolate=on, precision=1))\n",
    "\n",
    "plt.plot(freq_low[1:], ps_low[1:], label='low freq', alpha=0.7)\n",
    "plt.plot(freq_mid[1:], ps_mid[1:], label='mid freq', alpha=0.7)\n",
    "plt.plot(freq_high[1:], ps_high[1:], label='high freq', alpha=0.7)   \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ps_low.mean())\n",
    "print(ps_mid.mean())\n",
    "print(ps_high.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7409bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
