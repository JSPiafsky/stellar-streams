{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.typing as npt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from stellar_stream import StellarStream\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load all simulations into StellarStream type and put in a dictionary for easy access.\n",
    "\n",
    "from pathlib import Path\n",
    "p = Path('../../data/sample')\n",
    "graph = []\n",
    "\n",
    "simulations = {}\n",
    "\n",
    "for sim_data in p.glob('*.npz'):\n",
    "    simulation_number = sim_data.name.removeprefix('simdatag').removesuffix('.npz')\n",
    "    simulations[simulation_number] = (StellarStream.from_simulation(simulation_number, sim_data)\n",
    "                                    #  .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "                                    #  .select(\"restrict_phi2\", phi2_lim=10.0)\n",
    "                                    #  .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "                                    .run_analysis(name=\"gaussian_process_detrend\", n_bins=40)\n",
    "                                     .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "                                     .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657dc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in simulations.values():\n",
    "    sim.plot_power_spectrum(smooth=True, sigma=2, interpolate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06aeff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations['582'].plot_stream()\n",
    "simulations['582'].plot_density(smooth=True, sigma=2)\n",
    "simulations['582'].plot_power_spectrum(smooth=True, sigma=2, interpolate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791faabb",
   "metadata": {},
   "source": [
    "## How sensitive is dynamical heating measure to preprocessing chain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925864c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('../Data')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "heat_1 = {}\n",
    "heat_2 = {}\n",
    "heat_3 = {}\n",
    "\n",
    "for sim_data in p.glob('*.npz'):\n",
    "    simulation_number = sim_data.name.removeprefix('simdatag').removesuffix('.npz')\n",
    "    heat_1[simulation_number] = (StellarStream.from_simulation(simulation_number, sim_data)\n",
    "                                      .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "                                      .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "                                      .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "                                      .vlos.std(ddof=1))\n",
    "    \n",
    "    heat_2[simulation_number] = (StellarStream.from_simulation(simulation_number, sim_data)\n",
    "                                     .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "                                     .select(\"restrict_phi2\", phi2_lim=10.0)\n",
    "                                     .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "                                     .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "                                     .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "                                     .vlos.std(ddof=1))\n",
    "    heat_3[simulation_number] = (StellarStream.from_simulation(simulation_number, sim_data)\n",
    "                                     .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "                                     .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "                                     .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "                                     .vlos.std(ddof=1))\n",
    "\n",
    "    df[simulation_number] = pd.Series({\n",
    "        \"heat_1\": heat_1[simulation_number],\n",
    "        \"heat_2\": heat_2[simulation_number],\n",
    "        \"heat_3\": heat_3[simulation_number]\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308505fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "df.sort_index(axis=1, inplace=True)\n",
    "df.T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f14a28",
   "metadata": {},
   "source": [
    "## Using Skew to characterize wether a simulation still has a trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = StellarStream.from_simulation('716', '../Data/simdatag718.npz')\n",
    "S = (S\n",
    "    # .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "    # .select(\"restrict_phi2\", phi2_lim=10.0)\n",
    "    # .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "print(np.polyfit(S.phi1, S.phi2, 3))\n",
    "\n",
    "S.plot_stream()\n",
    "\n",
    "print(f'skew phi1: {skew(S.phi1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skew = pd.DataFrame()\n",
    "for key in simulations.keys():\n",
    "    df_skew[key] = pd.Series({\n",
    "    \"skew\": skew(simulations[key].phi1)\n",
    "    })\n",
    "\n",
    "df_skew.sort_index(axis=1,inplace=True)\n",
    "df_skew = df_skew.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eae4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c38d37",
   "metadata": {},
   "source": [
    "### B-Spline Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b419507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import make_lsq_spline, UnivariateSpline\n",
    "\n",
    "S = StellarStream.from_simulation('716', '../Data/simdatag718.npz')\n",
    "S = (S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=3.0))\n",
    "\n",
    "\n",
    "def fit_bspline(phi1, phi2, k=3, n_internal_knots=4, jitter_duplicate_x=False):\n",
    "    \"\"\"\n",
    "    Fit a least-squares B-spline to (phi1, phi2).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phi1, phi2 : array-like, same shape\n",
    "        Independent and dependent data.\n",
    "    k : int\n",
    "        Spline degree (default 3 = cubic).\n",
    "    n_internal_knots : int\n",
    "        Number of internal knots to place (evenly spaced) inside (min(phi1), max(phi1)).\n",
    "        If 0, a global polynomial spline of degree k is fitted.\n",
    "    jitter_duplicate_x : bool\n",
    "        If True, tiny jitter is added to duplicated phi1 values to avoid linear algebra errors.\n",
    "        If False, duplicated phi1 values are averaged (recommended if duplicates are real repeats).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spl : BSpline-like object (callable)\n",
    "        The fitted spline. Call with spl(x) to evaluate.\n",
    "    trend_phi2 : ndarray\n",
    "        spline evaluated at original phi1 (unsorted, same order as inputs).\n",
    "    residual_phi2 : ndarray\n",
    "        phi2 - trend_phi2\n",
    "    \"\"\"\n",
    "    phi1 = np.asarray(phi1)\n",
    "    phi2 = np.asarray(phi2)\n",
    "    if phi1.shape != phi2.shape:\n",
    "        raise ValueError(\"phi1 and phi2 must have the same shape\")\n",
    "\n",
    "    # sort by phi1 because make_lsq_spline expects x increasing\n",
    "    order = np.argsort(phi1)\n",
    "    x = phi1[order].astype(float)\n",
    "    y = phi2[order].astype(float)\n",
    "\n",
    "    # handle duplicates: average y for duplicate x (common approach)\n",
    "    uniq_x, inv_idx = np.unique(x, return_inverse=True)\n",
    "    if len(uniq_x) < len(x):\n",
    "        # average y for duplicate x\n",
    "        yy = np.zeros_like(uniq_x)\n",
    "        counts = np.zeros_like(uniq_x)\n",
    "        for i,u in enumerate(inv_idx):\n",
    "            yy[u] += y[i]\n",
    "            counts[u] += 1\n",
    "        yy /= counts\n",
    "        x = uniq_x\n",
    "        y = yy\n",
    "\n",
    "    if jitter_duplicate_x:\n",
    "        # add tiny jitter if duplicates still present (not usually necessary after averaging)\n",
    "        diffs = np.diff(x)\n",
    "        if np.any(diffs == 0):\n",
    "            x = x + np.random.normal(scale=1e-12 * np.ptp(x), size=x.shape)\n",
    "\n",
    "    # build internal knot vector (evenly spaced inside the open interval)\n",
    "    if n_internal_knots > 0:\n",
    "        t_internal = np.linspace(x[0], x[-1], n_internal_knots + 2)[1:-1]\n",
    "    else:\n",
    "        t_internal = np.asarray([])\n",
    "\n",
    "    # check that we have more data points than spline coefficients\n",
    "    # number of basis functions (coeffs) = len(t_internal) + k + 1\n",
    "    n_coeffs = len(t_internal) + k + 1\n",
    "    if x.size <= n_coeffs:\n",
    "        raise ValueError(\n",
    "            f\"Not enough data points ({x.size}) for the requested spline complexity \"\n",
    "            f\"(need > {n_coeffs} coefficients = n_internal_knots({len(t_internal)}) + k({k}) + 1). \"\n",
    "            \"Reduce n_internal_knots or degree k, or use more data.\"\n",
    "        )\n",
    "\n",
    "    # attempt LSQ-spline\n",
    "    try:\n",
    "        spl = make_lsq_spline(x, y, t_internal, k=k)\n",
    "    except Exception as e:\n",
    "        # fall back to a smoothing spline if LSQ-spline fails (gives a graceful alternative)\n",
    "        # choose an automatic smoothing factor: roughly variance * n_points\n",
    "        s = np.var(y) * max(1.0, x.size * 1e-3)\n",
    "        spl = UnivariateSpline(x, y, k=k, s=s)\n",
    "        # note: UnivariateSpline returns a similar callable interface\n",
    "\n",
    "    # evaluate at original (unsorted) phi1 order\n",
    "    trend = spl(phi1)    # spl accepts array-like\n",
    "    residual = phi2 - trend\n",
    "    return spl, trend, residual\n",
    "\n",
    "\n",
    "\n",
    "spl, trend_phi2, residual_phi2 = fit_bspline(S.phi1, S.phi2, k=1, n_internal_knots=2)\n",
    "\n",
    "# ensure we plot in increasing phi1 order so points/lines line up\n",
    "order_phi2 = np.argsort(S.phi1.values if hasattr(S.phi1, \"values\") else S.phi1)\n",
    "x_sorted = (S.phi1 if hasattr(S.phi1, \"values\") else S.phi1)[order_phi2]\n",
    "y_sorted = (S.phi2 if hasattr(S.phi2, \"values\") else S.phi2)[order_phi2]\n",
    "trend_sorted = trend_phi2[order_phi2]\n",
    "resid_sorted = residual_phi2[order_phi2]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# left: data + trend (also add a smooth spline curve for visual clarity)\n",
    "ax1.scatter(x_sorted, y_sorted, s=1, label='data')\n",
    "ax1.plot(x_sorted, trend_sorted, lw=1.5, label='spline trend', color='C1')\n",
    "# optional: smooth curve from the spline on a dense grid\n",
    "xx = np.linspace(x_sorted.min(), x_sorted.max(), 500)\n",
    "ax1.plot(xx, spl(xx), lw=1, linestyle='--', label='spline (dense grid)', alpha=0.7)\n",
    "ax1.set_title('phi2 and trend')\n",
    "ax1.set_xlabel('phi1')\n",
    "ax1.set_ylabel('phi2')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.2)\n",
    "\n",
    "# right: residuals\n",
    "ax2.scatter(x_sorted, resid_sorted, s=1)\n",
    "ax2.axhline(0, ls='--', lw=1, color='k')\n",
    "ax2.set_title('residual phi2 (data - trend)')\n",
    "ax2.set_xlabel('phi1')\n",
    "ax2.set_ylabel('residual')\n",
    "ax2.grid(True, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90056e",
   "metadata": {},
   "source": [
    "### Comparison of Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c98d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "(S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=6.0)\n",
    "    .plot_power_spectrum())\n",
    "\n",
    "(S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "    .select(\"restrict_phi2\", phi2_lim=15.0)\n",
    "    .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=6.0)\n",
    "    .plot_power_spectrum())\n",
    "\n",
    "(S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-110, 10))\n",
    "    .select(\"restrict_phi2\", phi2_lim=15.0)\n",
    "    .run_analysis(name=\"gaussian_detrend\", smoothing_scale=0.001)\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=6.0)\n",
    "    .plot_power_spectrum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d17461",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = StellarStream.from_simulation('656', '../Data/simdatag656.npz')\n",
    "\n",
    "(S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "    .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "    .plot_density())\n",
    "\n",
    "(S\n",
    "    .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "    .plot_density())\n",
    "\n",
    "(S\n",
    "    .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "    .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "    .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "    .plot_density())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad69e0",
   "metadata": {},
   "source": [
    "### Gaussian Filter Detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = StellarStream.from_simulation('584', '../Data/simdatag584.npz')\n",
    "# S = (S\n",
    "#     .run_analysis(name=\"detrend\", polynomial_fit_degree=4)\n",
    "#     .select(\"restrict_phi1\", phi1_lim=(-100, 0))\n",
    "#     .select(\"restrict_phi2\", phi2_lim=3.0)\n",
    "#     .plot_density())\n",
    "\n",
    "# convert to numpy arrays for computation but keep originals for re-wrapping\n",
    "phi1_orig = S.phi1\n",
    "phi2_orig = S.phi2\n",
    "vlos_orig = S.vlos\n",
    "\n",
    "x = np.asarray(phi1_orig, dtype=float)\n",
    "y_phi2 = np.asarray(phi2_orig, dtype=float)\n",
    "y_vlos = np.asarray(vlos_orig, dtype=float)\n",
    "\n",
    "# sort\n",
    "order_phi2 = np.argsort(x)\n",
    "x_sorted = x[order_phi2]\n",
    "phi2_sorted = y_phi2[order_phi2]\n",
    "vlos_sorted = y_vlos[order_phi2]\n",
    "\n",
    "# compute representative dx (ignore zero diffs from duplicates)\n",
    "diffs = np.diff(x_sorted)\n",
    "nonzero = diffs[np.abs(diffs) > 0]\n",
    "if nonzero.size == 0:\n",
    "    raise ValueError(\"phi1 has no spacing (all values equal). Cannot compute smoothing in pixel units.\")\n",
    "dx = np.median(nonzero)\n",
    "\n",
    "smoothing_scale=0.5\n",
    "# convert smoothing scale (same units as phi1) to pixels for gaussian_filter1d\n",
    "sigma_pix = float(smoothing_scale) / float(dx)\n",
    "if sigma_pix <= 0:\n",
    "    # sigma=0 means no smoothing; gaussian_filter1d with sigma=0 returns original array\n",
    "    sigma_pix = 0.0\n",
    "\n",
    "# apply Gaussian smoothing on the sorted data (reflect mode to reduce edge artifacts)\n",
    "# gaussian_filter1d accepts sigma==0 (no smoothing)\n",
    "phi2_trend_sorted = gaussian_filter1d(phi2_sorted, sigma_pix, mode='reflect')\n",
    "vlos_trend_sorted = gaussian_filter1d(vlos_sorted, sigma_pix, mode='reflect')\n",
    "\n",
    "# map the trends back to original order\n",
    "inverse_order = np.argsort(order_phi2)\n",
    "phi2_trend_orig = phi2_trend_sorted[inverse_order]\n",
    "vlos_trend_orig = vlos_trend_sorted[inverse_order]\n",
    "\n",
    "# detrend in original order\n",
    "phi2_detrend = np.asarray(phi2_orig, dtype=float) - phi2_trend_orig\n",
    "vlos_detrend = np.asarray(vlos_orig, dtype=float) - vlos_trend_orig\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "fig.suptitle(f'Stellar Stream Gaussian Detrend with {smoothing_scale} Pixel Smoothing')\n",
    "\n",
    "ax[0].scatter(x=phi1_orig, y=phi2_orig, s=0.1, label='Original')\n",
    "ax[0].scatter(x=phi1_orig, y=phi2_trend_orig, s=0.1, label='Trend')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(x=phi1_orig, y=phi2_detrend, s=0.1, label='Detrended')\n",
    "ax[1].legend()\n",
    "ax[1].axhline(0, ls='--', lw=1, color='k')\n",
    "\n",
    "ax[0].set_xlabel(r'$\\phi_1$')\n",
    "ax[1].set_xlabel(r'$\\phi_1$')\n",
    "ax[0].set_ylabel(r'$\\phi_2$')\n",
    "ax[1].set_ylabel(r'$\\phi_2$ Detrended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from celerite2 import GaussianProcess, terms\n",
    "import time\n",
    "\n",
    "S = StellarStream.from_simulation('580', '../Data/simdatag580.npz')\n",
    "\n",
    "def bin_data(x, y, n_bins=2000):\n",
    "    # x sorted assumed\n",
    "    edges = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "    idx = np.digitize(x, edges) - 1\n",
    "    idx[idx < 0] = 0\n",
    "    idx[idx >= n_bins] = n_bins - 1\n",
    "    xb = 0.5 * (edges[:-1] + edges[1:])\n",
    "    # compute mean y and std per bin (ignoring empty bins)\n",
    "    ysum = np.bincount(idx, weights=y, minlength=n_bins)\n",
    "    count = np.bincount(idx, minlength=n_bins)\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        ymean = ysum / count\n",
    "    mask = count > 0\n",
    "    return xb[mask], ymean[mask], count[mask]\n",
    "\n",
    "# prepare sorted data\n",
    "phi1 = np.asarray(S.phi1, dtype=float)\n",
    "phi2 = np.asarray(S.phi2, dtype=float)\n",
    "mask_phi2 = np.isfinite(phi1) & np.isfinite(phi2)\n",
    "phi1 = phi1[mask_phi2]; phi2 = phi2[mask_phi2]\n",
    "order_phi2 = np.argsort(phi1)\n",
    "phi1 = phi1[order_phi2]; phi2 = phi2[order_phi2]\n",
    "\n",
    "# bin: reduce to ~2000\n",
    "n_bins = 30\n",
    "xb, yb, counts = bin_data(phi1, phi2, n_bins=n_bins)\n",
    "\n",
    "# estimate uncertainties for binned points (std/sqrt(N) or use robust estimate)\n",
    "yerr_binned = np.sqrt(np.maximum(np.var(yb), 1e-6)) / np.sqrt(np.maximum(counts, 1))\n",
    "\n",
    "# auto initial guesses (as we used before)\n",
    "amp0 = max(np.std(phi2), 1e-6)\n",
    "stream_length = phi1.max() - phi1.min() if (phi1.max() > phi1.min()) else 1.0\n",
    "dx_med = np.median(np.diff(phi1))\n",
    "rho0 = max(stream_length / 8.0, 3.0 * dx_med, 1e-3)\n",
    "jitter0 = max(1e-3 * amp0, 1e-6)\n",
    "print(\"bin-fit: amp0, rho0, jitter0:\", amp0, rho0, jitter0)\n",
    "\n",
    "# Build celerite2 GP for binned data\n",
    "term = terms.SHOTerm(sigma=amp0, rho=rho0, Q=1.0)   # or try Matern32Term\n",
    "gp = GaussianProcess(term, mean=np.median(yb))\n",
    "gp.compute(xb, diag=(yerr_binned**2 + jitter0))\n",
    "\n",
    "# Fit only (log sigma, log rho, log jitter) - keep mean fixed\n",
    "def set_params(params, gp_local):\n",
    "    sigma = np.exp(params[0])\n",
    "    rho = np.exp(params[1])\n",
    "    jitter = np.exp(params[2])\n",
    "    gp_local.mean = np.median(yb)            # fixed mean\n",
    "    gp_local.kernel = terms.SHOTerm(sigma=sigma, rho=rho, Q=1.0)\n",
    "    gp_local.compute(xb, diag=(yerr_binned**2 + jitter), quiet=True)\n",
    "    return gp_local\n",
    "\n",
    "def neg_log_like(params):\n",
    "    g = set_params(params, gp)\n",
    "    return -g.log_likelihood(yb)\n",
    "\n",
    "p0 = np.array([np.log(amp0), np.log(rho0), np.log(jitter0)])\n",
    "t0 = time.time()\n",
    "sol = minimize(neg_log_like, p0, method=\"L-BFGS-B\", options={'maxiter':200})\n",
    "t_fit = time.time() - t0\n",
    "print(\"Fit done: success\", sol.success, \"msg:\", sol.message, \"time(s):\", t_fit)\n",
    "\n",
    "# set gp with fitted params\n",
    "gp = set_params(sol.x, gp)\n",
    "\n",
    "# Predict on full dataset (this is linear-time and quick)\n",
    "t0 = time.time()\n",
    "mu_full, var_full = gp.predict(yb, t=phi1, return_var=True)  # note: predict expects training y input; for celerite2 we pass yb (binned y) used for fit\n",
    "# However celerite2.predict requires you to pass the training y used when compute was called.\n",
    "# If you used the binned data to fit, pass yb for prediction calls; gp.compute was called with xb.\n",
    "t_pred = time.time() - t0\n",
    "print(\"Predict on full N time(s):\", t_pred)\n",
    "\n",
    "residuals = phi2 - mu_full\n",
    "\n",
    "\n",
    "# GP prediction at full resolution\n",
    "mu_full, var_full = gp.predict(yb, t=phi1, return_var=True)\n",
    "residuals = phi2 - mu_full\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(phi1, phi2, s=1, alpha=0.5, label=\"data\")\n",
    "plt.plot(phi1, mu_full, color=\"C1\", lw=2, label=\"GP trend\")\n",
    "plt.fill_between(phi1, mu_full-np.sqrt(var_full), mu_full+np.sqrt(var_full),\n",
    "                 color=\"C1\", alpha=0.3, label=\"GP ±1σ\")\n",
    "plt.legend()\n",
    "plt.title(\"Trend fit with celerite2\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(phi1, residuals, s=1, alpha=0.5, color=\"k\")\n",
    "plt.axhline(0, color=\"C1\", lw=2)\n",
    "plt.title(\"Residuals\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phi1_phi2_fit = np.polynomial.polynomial.Polynomial.fit(S.phi1, S.phi2, 4)\n",
    "phi2_detrend = S.phi2 - phi1_phi2_fit(S.phi1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(S.phi1, S.phi2, s=6, alpha=0.6, label='data')\n",
    "plt.plot(phi1_grid, phi1_phi2_fit(phi1_grid), color='C1', lw=2, label='celerite2 trend')\n",
    "plt.xlabel('phi1'); plt.ylabel('phi2'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(S.phi1, phi2_detrend, s=6)\n",
    "plt.axhline(0, color='k', ls='--')\n",
    "plt.xlabel('phi1'); plt.ylabel('residual (phi2 - trend)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "S = StellarStream.from_simulation('580', '../Data/simdatag580.npz')\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_process_detrend(self, n_bins):\n",
    "    def bin_data(x, y, n_bins=2000):\n",
    "        # x sorted assumed\n",
    "        edges = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "        idx = np.digitize(x, edges) - 1\n",
    "        idx[idx < 0] = 0\n",
    "        idx[idx >= n_bins] = n_bins - 1\n",
    "        xb = 0.5 * (edges[:-1] + edges[1:])\n",
    "        # compute mean y and std per bin (ignoring empty bins)\n",
    "        ysum = np.bincount(idx, weights=y, minlength=n_bins)\n",
    "        count = np.bincount(idx, minlength=n_bins)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            ymean = ysum / count\n",
    "        mask = count > 0\n",
    "        return xb[mask], ymean[mask], count[mask]\n",
    "\n",
    "    # prepare sorted data\n",
    "    phi1 = np.asarray(self.phi1, dtype=float)\n",
    "    phi2 = np.asarray(self.phi2, dtype=float)\n",
    "    vlos = np.asarray(self.vlos, dtype=float)\n",
    "    mask_phi2 = np.isfinite(phi1) & np.isfinite(phi2) & np.isfinite(vlos)\n",
    "    phi1 = phi1[mask_phi2]; phi2 = phi2[mask_phi2]; vlos = vlos[mask_phi2]\n",
    "    order_phi2 = np.argsort(phi1)\n",
    "    phi1 = phi1[order_phi2]; phi2 = phi2[order_phi2]\n",
    "\n",
    "    # bin: reduce to ~2000\n",
    "    xb, yb, counts = bin_data(phi1, phi2, n_bins=n_bins)\n",
    "\n",
    "    # estimate uncertainties for binned points (std/sqrt(N) or use robust estimate)\n",
    "    yerr_binned = np.sqrt(np.maximum(np.var(yb), 1e-6)) / np.sqrt(np.maximum(counts, 1))\n",
    "\n",
    "    # auto initial guesses (as we used before)\n",
    "    amp0 = max(np.std(phi2), 1e-6)\n",
    "    stream_length = phi1.max() - phi1.min() if (phi1.max() > phi1.min()) else 1.0\n",
    "    dx_med = np.median(np.diff(phi1))\n",
    "    rho0 = max(stream_length / 8.0, 3.0 * dx_med, 1e-3)\n",
    "    jitter0 = max(1e-3 * amp0, 1e-6)\n",
    "\n",
    "    # Build celerite2 GP for binned data\n",
    "    term = terms.SHOTerm(sigma=amp0, rho=rho0, Q=1.0)   # or try Matern32Term\n",
    "    gp = GaussianProcess(term, mean=np.median(yb))\n",
    "    gp.compute(xb, diag=(yerr_binned**2 + jitter0))\n",
    "\n",
    "    # Fit only (log sigma, log rho, log jitter) - keep mean fixed\n",
    "    def set_params(params, gp_local):\n",
    "        sigma = np.exp(params[0])\n",
    "        rho = np.exp(params[1])\n",
    "        jitter = np.exp(params[2])\n",
    "        gp_local.mean = np.median(yb)            # fixed mean\n",
    "        gp_local.kernel = terms.SHOTerm(sigma=sigma, rho=rho, Q=1.0)\n",
    "        gp_local.compute(xb, diag=(yerr_binned**2 + jitter), quiet=True)\n",
    "        return gp_local\n",
    "\n",
    "    def neg_log_like(params):\n",
    "        g = set_params(params, gp)\n",
    "        return -g.log_likelihood(yb)\n",
    "\n",
    "    p0 = np.array([np.log(amp0), np.log(rho0), np.log(jitter0)])\n",
    "    sol = minimize(neg_log_like, p0, method=\"L-BFGS-B\", options={'maxiter':200})\n",
    "\n",
    "    # set gp with fitted params\n",
    "    gp = set_params(sol.x, gp)\n",
    "\n",
    "    # GP prediction at full resolution\n",
    "    mu_full, var_full = gp.predict(yb, t=phi1, return_var=True)\n",
    "    phi2_detrend = phi2 - mu_full\n",
    "    \n",
    "    return StellarStream(self.phi1, phi2_detrend, vlos_detrend, name=self.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stellar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
